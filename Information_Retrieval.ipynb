{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a9f875",
   "metadata": {},
   "source": [
    "search engines were lexical: the search engine looked for literal matches of the query words, without understanding of the query’s meaning and only returning links that contained the exact query.By using regular keyword search, a document either contains the given word or not, and there is no middle ground\n",
    "\n",
    "On the other hand, \"Semantic Search\" can simplify query building, becuase it is supported by automated natural language processing programs i.e. using Latent Semantic Indexing - a concept that search engines use to discover how a keyword and content work together to mean the same thing.\n",
    "\n",
    "LSI adds an important step to the document indexing process. LSI examines a collection of documents to see which documents contain some of those same words. LSI considers documents that have many words in common to be semantically close, and ones with less words in common to be less close.\n",
    "\n",
    "In brief, LSI does not require an exact match to return useful results. Where a plain keyword search will fail if there is no exact match, LSI will often return relevant documents that don't contain the keyword at all.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "***\n",
    "# Sumário\n",
    "\n",
    "* # 1. [Análise exploratória](#analise_expl)\n",
    "    * ## 1.1. [Carregando dados](#analise_expl)\n",
    "    * ## 1.2. [Pré-preocessamento: limpar e preparar dados](#limpar_preparar)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "* # 2. [Construção do Índice](#construcao_ind)\n",
    "Keyword Search Vs Semantic Search\n",
    "At first, search engines were lexical: the search engine looked for literal matches of the query words, without understanding of the query’s meaning and only returning links that contained the exact query.By using regular keyword search, a document either contains the given word or not, and there is no middle ground\n",
    "\n",
    "On the other hand, \"Semantic Search\" can simplify query building, becuase it is supported by automated natural language processing programs i.e. using Latent Semantic Indexing - a concept that search engines use to discover how a keyword and content work together to mean the same thin\n",
    "<br>\n",
    "\n",
    "\n",
    "* # 3. [Ranking](#ranking)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "* # 4. [Análise dos resultados](#analise_result)\n",
    "\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f1d173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 20:21:42.737930: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#importar bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#processamento de linguagem natural\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "\n",
    "#modelo\n",
    "import tensorflow as tf\n",
    "#metricas\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c6d2c6",
   "metadata": {},
   "source": [
    "<a id='analise_expl'></a>\n",
    "#  1. Análise exploratória\n",
    "\n",
    "Nesse estagio, vou me familiarizar com os dados para criar intuição sobre o problema e assim, ser capaz de começar a formular hipóteses testáveis.\n",
    "\n",
    "Nesse estagio, irei utilizar de vizualizacao e estatistica.\n",
    "\n",
    "## 1.1. Carregando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d2ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = pd.read_csv(\"../dados/pairs.csv\")#, delimiter=\";\")\n",
    "df_products = pd.read_csv(\"../dados/products.csv\")#, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a270c",
   "metadata": {},
   "source": [
    "## 1.2.: Entendendo os dados\n",
    "Vamos olhar para as caracteristicas basicas do banco de dados\n",
    "* Dataframe shape\n",
    "* head and tail\n",
    "* dtypes\n",
    "* estatisticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2253dca",
   "metadata": {},
   "source": [
    "Vamos começar vendo o que tem dentro de cada dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bfb2f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89832 entries, 0 to 89831\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   pair_id            89832 non-null  int64 \n",
      " 1   product_id         89832 non-null  int64 \n",
      " 2   query              89832 non-null  object\n",
      " 3   search_position    89832 non-null  int64 \n",
      " 4   print_count_query  89832 non-null  int64 \n",
      " 5   view_count_query   89832 non-null  int64 \n",
      " 6   cart_count_query   89832 non-null  int64 \n",
      " 7   order_count_query  89832 non-null  int64 \n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 5.5+ MB\n",
      "None\n",
      "(89832, 8)\n"
     ]
    }
   ],
   "source": [
    "# features da relação entre o par query e produto\n",
    "print(df_pairs.info())\n",
    "print(df_pairs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14b628d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>query</th>\n",
       "      <th>search_position</th>\n",
       "      <th>print_count_query</th>\n",
       "      <th>view_count_query</th>\n",
       "      <th>cart_count_query</th>\n",
       "      <th>order_count_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8589934593</td>\n",
       "      <td>14817</td>\n",
       "      <td>Convite Padrinhos Batismo</td>\n",
       "      <td>319</td>\n",
       "      <td>2374</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8589934636</td>\n",
       "      <td>14884</td>\n",
       "      <td>Decoracao De Casamento</td>\n",
       "      <td>254</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8589934836</td>\n",
       "      <td>8589934668</td>\n",
       "      <td>Toalha De Lavabo</td>\n",
       "      <td>233</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8589934727</td>\n",
       "      <td>17179884005</td>\n",
       "      <td>Calendario 2023 Editavel</td>\n",
       "      <td>40</td>\n",
       "      <td>4871</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8589934934</td>\n",
       "      <td>25769803777</td>\n",
       "      <td>Ecobag</td>\n",
       "      <td>286</td>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pair_id   product_id                      query  search_position  \\\n",
       "0  8589934593        14817  Convite Padrinhos Batismo              319   \n",
       "1  8589934636        14884     Decoracao De Casamento              254   \n",
       "2  8589934836   8589934668           Toalha De Lavabo              233   \n",
       "3  8589934727  17179884005   Calendario 2023 Editavel               40   \n",
       "4  8589934934  25769803777                     Ecobag              286   \n",
       "\n",
       "   print_count_query  view_count_query  cart_count_query  order_count_query  \n",
       "0               2374                18                 1                  0  \n",
       "1                388                 1                 0                  0  \n",
       "2                219                 2                 0                  0  \n",
       "3               4871                 2                 0                  0  \n",
       "4                166                 3                 0                  0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56b5ee",
   "metadata": {},
   "source": [
    "Coluna com texto:\n",
    "* query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d7dd260",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 76711 entries, 0 to 76769\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   product_id           76711 non-null  int64  \n",
      " 1   title                76711 non-null  object \n",
      " 2   tags                 76711 non-null  object \n",
      " 3   creation_date        76711 non-null  object \n",
      " 4   price                76711 non-null  float64\n",
      " 5   weight               76711 non-null  float64\n",
      " 6   express_delivery     76711 non-null  int64  \n",
      " 7   category             76711 non-null  object \n",
      " 8   minimum_quantity     76711 non-null  int64  \n",
      " 9   print_count_product  76711 non-null  int64  \n",
      " 10  view_count_product   76711 non-null  int64  \n",
      " 11  cart_count_product   76711 non-null  int64  \n",
      " 12  order_count_product  76711 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 8.2+ MB\n",
      "None\n",
      "(76711, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_products.info())\n",
    "print(df_products.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dfe5a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>express_delivery</th>\n",
       "      <th>category</th>\n",
       "      <th>minimum_quantity</th>\n",
       "      <th>print_count_product</th>\n",
       "      <th>view_count_product</th>\n",
       "      <th>cart_count_product</th>\n",
       "      <th>order_count_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Jogo Banheiro de Crochê de 3 Peças</td>\n",
       "      <td>['#jogobanheiro #croche #tapetes', 'decoração'...</td>\n",
       "      <td>2022-09-25 13:43:36</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Técnicas de Artesanato</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>Guardanapos de Tecido - 100 unidades</td>\n",
       "      <td>['guardanapos de tecido', 'guradanapo', 'festa...</td>\n",
       "      <td>2014-12-26 18:47:48</td>\n",
       "      <td>269.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Casa</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Toalha Papai Noel</td>\n",
       "      <td>['natal', 'toalha de natal', 'toalha de mesa',...</td>\n",
       "      <td>2013-11-06 20:43:27</td>\n",
       "      <td>291.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Casa</td>\n",
       "      <td>1</td>\n",
       "      <td>423</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8589941942</td>\n",
       "      <td>Caixa para 1 bis feliz natal cliente como você...</td>\n",
       "      <td>['lembrança', 'personalizados', 'festa', 'caix...</td>\n",
       "      <td>2021-11-22 15:02:30</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lembrancinhas</td>\n",
       "      <td>30</td>\n",
       "      <td>2746</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17179869192</td>\n",
       "      <td>Árvore de Natal decorada em MDF</td>\n",
       "      <td>['#madajoartesanato', '#decoraçaodenatal', '#e...</td>\n",
       "      <td>2020-12-18 18:52:35</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Decoração</td>\n",
       "      <td>1</td>\n",
       "      <td>1010</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id                                              title  \\\n",
       "0          101                 Jogo Banheiro de Crochê de 3 Peças   \n",
       "1          106               Guardanapos de Tecido - 100 unidades   \n",
       "2           47                                  Toalha Papai Noel   \n",
       "3   8589941942  Caixa para 1 bis feliz natal cliente como você...   \n",
       "4  17179869192                    Árvore de Natal decorada em MDF   \n",
       "\n",
       "                                                tags        creation_date  \\\n",
       "0  ['#jogobanheiro #croche #tapetes', 'decoração'...  2022-09-25 13:43:36   \n",
       "1  ['guardanapos de tecido', 'guradanapo', 'festa...  2014-12-26 18:47:48   \n",
       "2  ['natal', 'toalha de natal', 'toalha de mesa',...  2013-11-06 20:43:27   \n",
       "3  ['lembrança', 'personalizados', 'festa', 'caix...  2021-11-22 15:02:30   \n",
       "4  ['#madajoartesanato', '#decoraçaodenatal', '#e...  2020-12-18 18:52:35   \n",
       "\n",
       "   price  weight  express_delivery                category  minimum_quantity  \\\n",
       "0  110.0     1.0                 1  Técnicas de Artesanato                 1   \n",
       "1  269.5     0.0                 0                    Casa                 1   \n",
       "2  291.1     0.0                 0                    Casa                 1   \n",
       "3   45.0     0.0                 0           Lembrancinhas                30   \n",
       "4  100.0     0.0                 0               Decoração                 1   \n",
       "\n",
       "   print_count_product  view_count_product  cart_count_product  \\\n",
       "0                   11                   0                   0   \n",
       "1                   62                   6                   0   \n",
       "2                  423                   4                   0   \n",
       "3                 2746                  93                   6   \n",
       "4                 1010                   4                   0   \n",
       "\n",
       "   order_count_product  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    2  \n",
       "4                    0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features de produtos\n",
    "df_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e948f01d",
   "metadata": {},
   "source": [
    "colunas de texto\n",
    "* title\n",
    "* tags \n",
    "* category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7726eccf",
   "metadata": {},
   "source": [
    "### Estatisticas dos dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0fb9ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>express_delivery</th>\n",
       "      <th>minimum_quantity</th>\n",
       "      <th>print_count_product</th>\n",
       "      <th>view_count_product</th>\n",
       "      <th>cart_count_product</th>\n",
       "      <th>order_count_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76711.000000</td>\n",
       "      <td>76711.000000</td>\n",
       "      <td>76711.000000</td>\n",
       "      <td>76711.000000</td>\n",
       "      <td>76711.000000</td>\n",
       "      <td>76711.000000</td>\n",
       "      <td>76711.000000</td>\n",
       "      <td>76711.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>205.439692</td>\n",
       "      <td>282.893223</td>\n",
       "      <td>0.175490</td>\n",
       "      <td>13.016477</td>\n",
       "      <td>2077.774856</td>\n",
       "      <td>53.246497</td>\n",
       "      <td>1.836425</td>\n",
       "      <td>0.363025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>566.132438</td>\n",
       "      <td>1239.292652</td>\n",
       "      <td>0.380388</td>\n",
       "      <td>71.227281</td>\n",
       "      <td>12073.890932</td>\n",
       "      <td>134.071726</td>\n",
       "      <td>5.568000</td>\n",
       "      <td>1.432096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>97.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>199.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43150.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>685904.000000</td>\n",
       "      <td>5162.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price        weight  express_delivery  minimum_quantity  \\\n",
       "count  76711.000000  76711.000000      76711.000000      76711.000000   \n",
       "mean     205.439692    282.893223          0.175490         13.016477   \n",
       "std      566.132438   1239.292652          0.380388         71.227281   \n",
       "min        9.900000      0.000000          0.000000          1.000000   \n",
       "25%       45.000000      0.000000          0.000000          1.000000   \n",
       "50%       97.140000      0.000000          0.000000          1.000000   \n",
       "75%      199.000000    180.000000          0.000000         10.000000   \n",
       "max    43150.000000  50000.000000          1.000000       7000.000000   \n",
       "\n",
       "       print_count_product  view_count_product  cart_count_product  \\\n",
       "count         76711.000000        76711.000000        76711.000000   \n",
       "mean           2077.774856           53.246497            1.836425   \n",
       "std           12073.890932          134.071726            5.568000   \n",
       "min               0.000000            0.000000            0.000000   \n",
       "25%              64.000000            5.000000            0.000000   \n",
       "50%             378.000000           16.000000            1.000000   \n",
       "75%            1461.000000           47.000000            2.000000   \n",
       "max          685904.000000         5162.000000          446.000000   \n",
       "\n",
       "       order_count_product  \n",
       "count         76711.000000  \n",
       "mean              0.363025  \n",
       "std               1.432096  \n",
       "min               0.000000  \n",
       "25%               0.000000  \n",
       "50%               0.000000  \n",
       "75%               0.000000  \n",
       "max             143.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products.drop('product_id', axis=1).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68647563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b76ca5c",
   "metadata": {},
   "source": [
    "<a id='limpar_preparar'></a>\n",
    "#  1.2. Pré-processamento: limpar e preparar dados\n",
    "\n",
    "Vamos preparar/limpar nossos dados para a análise exploratoria. Para decidir o que fazer nesse estagio, vamos relembrar qual é o nosso problema: queremos criar um modelo que seja capaz de, dada uma query, retornar produtos mais relevantes (baseados nas suas descricoes) e recomendar produtos diferentes.\n",
    "\n",
    "Fazer keyword search para resol\n",
    "Se utilizarmos semantic search para resolver o problema,  Semantic search attempts to apply user intent and the meaning (or semantics) of words and phrases to find the right content.\n",
    "\n",
    "It goes beyond keyword matching by using information that might not be present immediately in the text (the keywords themselves) but is closely tied to what the searcher wants.\n",
    "\n",
    "\n",
    "Portanto, no estagio de limpeza de dados é interessante:\n",
    "* Que o algoritmo seja capaz de detectar palavras com errors ortograficos como iguais. Ex:\n",
    "            guardanapos = gurdanapo\n",
    "            aniversário = aniversario\n",
    "            \n",
    "* remover captalizacao, para que o algoritmo nao diferencie, por ex.: guardanapos de Guardanapos\n",
    "\n",
    "* Queremos remover inflexoes das palavras -> lemmetizacao\n",
    "\n",
    "* Remover palavras que nao acrescentam signifcado ao texto (stopwords)\n",
    "\n",
    "\n",
    "\n",
    "Assim, seguiremos as seguintes etapas:\n",
    "\n",
    "* 1. Remover Null values\n",
    "* 2. Tokenization \n",
    "* 3. Remover pontuações\n",
    "* 4. Remover stopwords\n",
    "* 5. Converter todos os caracteres para letras minusculas\n",
    "* 6. Lemmatization\n",
    "* 7. Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373ec90",
   "metadata": {},
   "source": [
    "## 1.2.1. Remover Null values\n",
    "Vamos examinar se temos algum valor faltante nos dataframes. Dos outputs abaixo, parece que apenas as colunas **weight** e **category** do dataframe **df_products** tem valores faltantes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bcc5456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- df_pairs ----\n",
      "pair_id 0\n",
      "product_id 0\n",
      "query 0\n",
      "search_position 0\n",
      "print_count_query 0\n",
      "view_count_query 0\n",
      "cart_count_query 0\n",
      "order_count_query 0\n",
      "\n",
      "\n",
      "---- df_products ----\n",
      "product_id 0\n",
      "title 0\n",
      "tags 0\n",
      "creation_date 0\n",
      "price 0\n",
      "weight 51\n",
      "express_delivery 0\n",
      "category 8\n",
      "minimum_quantity 0\n",
      "print_count_product 0\n",
      "view_count_product 0\n",
      "cart_count_product 0\n",
      "order_count_product 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---- df_pairs ----\")\n",
    "for col in df_pairs.columns:\n",
    "    print(col, df_pairs[col].isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"---- df_products ----\")\n",
    "for col in df_products.columns:\n",
    "    print(col, df_products[col].isnull().sum())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129dd71",
   "metadata": {},
   "source": [
    "Removendo *linhas* com valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2a455c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- df_products ----\n",
      "product_id 0\n",
      "title 0\n",
      "tags 0\n",
      "creation_date 0\n",
      "price 0\n",
      "weight 0\n",
      "express_delivery 0\n",
      "category 0\n",
      "minimum_quantity 0\n",
      "print_count_product 0\n",
      "view_count_product 0\n",
      "cart_count_product 0\n",
      "order_count_product 0\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 76711 entries, 0 to 76769\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   product_id           76711 non-null  int64  \n",
      " 1   title                76711 non-null  object \n",
      " 2   tags                 76711 non-null  object \n",
      " 3   creation_date        76711 non-null  object \n",
      " 4   price                76711 non-null  float64\n",
      " 5   weight               76711 non-null  float64\n",
      " 6   express_delivery     76711 non-null  int64  \n",
      " 7   category             76711 non-null  object \n",
      " 8   minimum_quantity     76711 non-null  int64  \n",
      " 9   print_count_product  76711 non-null  int64  \n",
      " 10  view_count_product   76711 non-null  int64  \n",
      " 11  cart_count_product   76711 non-null  int64  \n",
      " 12  order_count_product  76711 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_products.dropna(inplace=True)\n",
    "\n",
    "print(\"---- df_products ----\")\n",
    "for col in df_products.columns:\n",
    "    print(col, df_products[col].isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "df_products.info()\n",
    "#removemos 59 linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db21094",
   "metadata": {},
   "source": [
    "<a id='pontuacao'></a>\n",
    "\n",
    "\n",
    "## 1.2.2 Remover pontuação e tokenizar\n",
    "\n",
    "Anteriormente, vimos que as colunas que contem dados em forma de texto sao:\n",
    "* em df_pair:\n",
    "    * query\n",
    "    \n",
    "* em df_products:\n",
    "    * title\n",
    "    * tags \n",
    "    * category    \n",
    "\n",
    "Com os pré-processamentos, queremos reduzir o tamanho do vocabulário e simplificar algumas formas lexicais, garantindo, assim, que o algoritmo obtenha informações relevantes e que de fato representam o nosso os produtos e as queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_pairs = df_pairs.copy()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "dfada185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chamar modelo em portugues\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cccc9d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gabriela/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#criar uma lista com pontuações\n",
    "punctuations = string.punctuation \n",
    "print(punctuations)\n",
    "\n",
    "# criar uma lista de stop words em portugues\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# para escolher as stopwords do português adicionamos a opçaõ de língua \"portuguese\"\n",
    "stop_words = nltk.corpus.stopwords.words('portuguese')\n",
    "print(stop_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e4dc4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(sentence):\n",
    "    \n",
    "    #normalizar: converter todas as strings para letra minuscula\n",
    "    sentence.lower\n",
    "\n",
    "    #criar objeto token \n",
    "    tokens = nlp(sentence)\n",
    "  \n",
    "    #remover stopwords, pontuacao, simbolos especiais, palavras com menos de 2 caracteres\n",
    "    #e lematizar e remover espacos depois de tokens\n",
    "    \n",
    "    tokens = [word.lemma_.strip() for word in tokens if str(word) not in stop_words\\\n",
    "                                     and str(word) not in punctuations\\\n",
    "                                     and len(word)>2]\n",
    "    \n",
    "    #replace extra spaces with single space\n",
    "    sentence = re.sub(' +',' ',sentence)\n",
    "\n",
    "    #remove unwanted lines starting from special characters\n",
    "    sentence = re.sub(r'\\n: \\'\\'.*','',sentence)\n",
    "    sentence = re.sub(r'\\n!.*','',sentence)\n",
    "    sentence = re.sub(r'^:\\'\\'.*','',sentence)\n",
    "    \n",
    "    #remove non-breaking new line characters\n",
    "    sentence = re.sub(r'\\n',' ',sentence)\n",
    "    \n",
    "    #remove punctunations\n",
    "    sentence = re.sub(r'[^\\w\\s]',' ',sentence)\n",
    "\n",
    "    \n",
    "    \n",
    "    #return tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b6767d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cleaning and Tokenizing...')\n",
    "%time df2_products['query_tokenized'] = df2_products['query'].map(lambda x: tokenizer(x))\n",
    "\n",
    "df2_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "93433c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and Tokenizing...\n",
      "CPU times: user 88.6 ms, sys: 3.59 ms, total: 92.2 ms\n",
      "Wall time: 89.6 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>query</th>\n",
       "      <th>search_position</th>\n",
       "      <th>print_count_query</th>\n",
       "      <th>view_count_query</th>\n",
       "      <th>cart_count_query</th>\n",
       "      <th>order_count_query</th>\n",
       "      <th>query_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8589934593</td>\n",
       "      <td>14817</td>\n",
       "      <td>Convite Padrinhos Batismo</td>\n",
       "      <td>319</td>\n",
       "      <td>2374</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Convite, Padrinhos, Batismo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8589934636</td>\n",
       "      <td>14884</td>\n",
       "      <td>Decoracao De Casamento</td>\n",
       "      <td>254</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Decoracao, Casamento]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8589934836</td>\n",
       "      <td>8589934668</td>\n",
       "      <td>Toalha De Lavabo</td>\n",
       "      <td>233</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Toalha, Lavabo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8589934727</td>\n",
       "      <td>17179884005</td>\n",
       "      <td>Calendario 2023 Editavel</td>\n",
       "      <td>40</td>\n",
       "      <td>4871</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Calendario, 2023, editavel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8589934934</td>\n",
       "      <td>25769803777</td>\n",
       "      <td>Ecobag</td>\n",
       "      <td>286</td>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Ecobag]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pair_id   product_id                      query  search_position  \\\n",
       "0  8589934593        14817  Convite Padrinhos Batismo              319   \n",
       "1  8589934636        14884     Decoracao De Casamento              254   \n",
       "2  8589934836   8589934668           Toalha De Lavabo              233   \n",
       "3  8589934727  17179884005   Calendario 2023 Editavel               40   \n",
       "4  8589934934  25769803777                     Ecobag              286   \n",
       "\n",
       "   print_count_query  view_count_query  cart_count_query  order_count_query  \\\n",
       "0               2374                18                 1                  0   \n",
       "1                388                 1                 0                  0   \n",
       "2                219                 2                 0                  0   \n",
       "3               4871                 2                 0                  0   \n",
       "4                166                 3                 0                  0   \n",
       "\n",
       "                 query_tokenized  \n",
       "0  [Convite, Padrinhos, Batismo]  \n",
       "1         [Decoracao, Casamento]  \n",
       "2               [Toalha, Lavabo]  \n",
       "3   [Calendario, 2023, editavel]  \n",
       "4                       [Ecobag]  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Cleaning and Tokenizing...')\n",
    "%time df2_pairs['query_tokenized'] = df2_pairs['query'].map(lambda x: tokenizer(x))\n",
    "\n",
    "df2_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "54c664e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags_tokenized</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jogobanheiro, croche, tapete, decoração, cor,...</td>\n",
       "      <td>['#jogobanheiro #croche #tapetes', 'decoração'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[guardanapo, tecido, guradanapo, festa, evento...</td>\n",
       "      <td>['guardanapos de tecido', 'guradanapo', 'festa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[natal, toalha, natal, toalha, mesa, papai, no...</td>\n",
       "      <td>['natal', 'toalha de natal', 'toalha de mesa',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[lembrança, personalizar, festa, caixa, caixin...</td>\n",
       "      <td>['lembrança', 'personalizados', 'festa', 'caix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[madajoartesanato, decoraçaodenatal, enfeitede...</td>\n",
       "      <td>['#madajoartesanato', '#decoraçaodenatal', '#e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tags_tokenized  \\\n",
       "0  [jogobanheiro, croche, tapete, decoração, cor,...   \n",
       "1  [guardanapo, tecido, guradanapo, festa, evento...   \n",
       "2  [natal, toalha, natal, toalha, mesa, papai, no...   \n",
       "3  [lembrança, personalizar, festa, caixa, caixin...   \n",
       "4  [madajoartesanato, decoraçaodenatal, enfeitede...   \n",
       "\n",
       "                                                tags  \n",
       "0  ['#jogobanheiro #croche #tapetes', 'decoração'...  \n",
       "1  ['guardanapos de tecido', 'guradanapo', 'festa...  \n",
       "2  ['natal', 'toalha de natal', 'toalha de mesa',...  \n",
       "3  ['lembrança', 'personalizados', 'festa', 'caix...  \n",
       "4  ['#madajoartesanato', '#decoraçaodenatal', '#e...  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_products[['tags_tokenized', 'tags']].head()\n",
    "#palavras duplicadas\n",
    "#talvez seja melhor tokenizar frases curtas do que palavras individuais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51cbf867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#regular expressions biblioteca para detectar padroes em texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01515900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A menina de azul \"é\" bonita.    Ela anda de bicicleta e tem 1 laço"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('A menina de azul \"é\" bonita. Ela anda de bicicleta e tem 1 laço')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef3e3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(sentence):\n",
    " \n",
    "    #remove distracting single quotes\n",
    "    sentence = re.sub('\\'','',sentence)\n",
    "\n",
    "    #remove digits adnd words containing digits\n",
    "    sentence = re.sub('\\w*\\d\\w*','',sentence)\n",
    "\n",
    "    #replace extra spaces with single space\n",
    "    sentence = re.sub(' +',' ',sentence)\n",
    "\n",
    "    #remove unwanted lines starting from special characters\n",
    "    sentence = re.sub(r'\\n: \\'\\'.*','',sentence)\n",
    "    sentence = re.sub(r'\\n!.*','',sentence)\n",
    "    sentence = re.sub(r'^:\\'\\'.*','',sentence)\n",
    "    \n",
    "    #remove non-breaking new line characters\n",
    "    sentence = re.sub(r'\\n',' ',sentence)\n",
    "    \n",
    "    #remove punctunations\n",
    "    sentence = re.sub(r'[^\\w\\s]',' ',sentence)\n",
    "    \n",
    "    #creating token object\n",
    "    tokens = nlp(sentence)\n",
    "    \n",
    "    #lower, strip and lemmatize\n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens]\n",
    "    \n",
    "    #remove stopwords, and exclude words less than 2 characters\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in punctuations and len(word) > 2]\n",
    "    \n",
    "    #return tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dcc8088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A menina de azul \"é\" bonita.     Ela anda de bicicleta e tem 1 laço\n",
      "A menina de azul \"é\" bonita.    Ela anda de bicicleta e tem  laço\n",
      "A menina de azul \"é\" bonita.    Ela anda de bicicleta e tem 1 laço\n"
     ]
    }
   ],
   "source": [
    "print(re.sub('\\'','','A menina de azul \"é\" bonita.     Ela anda de bicicleta e tem 1 laço'))\n",
    "print(re.sub('\\w*\\d\\w*','','A menina de azul \"é\" bonita.    Ela anda de bicicleta e tem 1 laço'))\n",
    "print(re.sub(r'\\n: \\'\\'.*','','A menina de azul \"é\" bonita.    Ela anda de bicicleta e tem 1 laço'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109816da",
   "metadata": {},
   "source": [
    "Vamos aplicar a funcao de data-cleaning e pre-processamento nas colunas \"query\", \"tags\", \"category\", \"title\" column and store the cleaned, tokenized data into new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f087c564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enelvo.normaliser.Normaliser at 0x7ff0cca8feb0>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = Normaliser(tokenizer='readable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1756529a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c1b1623",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2804356022.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[45], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    re.sub('\\\"\",'','A menina de azul \"é\" bonita. Ela anda de bicicleta')\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Normaliser(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6458ed04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and Tokenizing...\n",
      "CPU times: user 94.9 ms, sys: 3.72 ms, total: 98.6 ms\n",
      "Wall time: 96.6 ms\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10 entries, 0 to 9\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   tags            10 non-null     object\n",
      " 1   tags_tokenized  10 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 240.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "print ('Cleaning and Tokenizing...')\n",
    "%time a['tags_tokenized'] = a['tags'].map(lambda x: tokenizer(x))\n",
    "\n",
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb02b09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#jogobanheiro #croche #tapetes', 'decoração', 'nas cores chumbo e rosa bebê']\n",
      "['jogobanheiro', 'croche', 'tapete', 'decoração', 'em o', 'cor', 'chumbo', 'roso', 'bebê']\n"
     ]
    }
   ],
   "source": [
    "print(a['tags'][0])\n",
    "print(a['tags_tokenized'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99532398",
   "metadata": {},
   "source": [
    "<a id='tokenization'></a>\n",
    "\n",
    "\n",
    "## 1.2.3 Tokenization\n",
    "\n",
    "Vamos quebrar os textos bruto em pedaços menores - tokens. Lembrando que anteriormente, vimos que as colunas que contem dados em forma de texto sao:\n",
    "\n",
    "* em df_pair:\n",
    "    * query\n",
    "    \n",
    "* em df_products:\n",
    "    * title\n",
    "    * tags \n",
    "    * category\n",
    "    \n",
    "Vamos comecar, removendo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a2bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e704d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c546e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8878d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df97c14c",
   "metadata": {},
   "source": [
    "# Sistema de recomendação: Content-Based Filtering\n",
    "A recomendação é feita baseada nas **features de usuário** e nas **features dos produtos**. O match entre usuario e produto é feito pelo produto escalar:\n",
    "\n",
    "## $ y^{i,j} = \\vec{v}_{u}^{i}\\cdot \\vec{v}_{p}^{j}$\n",
    "\n",
    "onde $\\vec{v}_{u}^{i}$ e $\\vec{v}_{p}^{j}$ são vetores computados das features do usuario $i$ e do produto $j$, respetivamente.\n",
    "\n",
    "Muitos algoritmos de content-based filtering estimam $\\vec{v}_{u}^{i}$ e  $\\vec{v}_{p}^{j}$ usando redes neurais com a seguinte funcao de de custo:\n",
    "## $J = \\sum_{i,j}\\left( \\vec{v}_{u}^{i}\\cdot \\vec{v}_{p}^{j} -  y^{i,j} \\right)^2 + \\text{termos de regularização}$\n",
    "\n",
    "Esse algoritmo tambem pode ser utilizado para *encontrar produtos similares*. Para isso, calculamos a distancia entre as features\n",
    "## $ ||\\vec{v}_{u}^{i} - \\vec{v}_{p}^{j}||^2$\n",
    "\n",
    "# Recomendação em grandes catálogos\n",
    "O banco de dados contem mais de 6 milhoes de produtos. Portanto, o algoritmo pode ser computacionalmente inviavel de rodar para tantos itens. Para remediar esse problema, podemos implementar o sistema de recomendação em duas etapas: **retrieval** e **ranking**.\n",
    "\n",
    "## Retrieval\n",
    "Gerar uma lista de produtos plausiveis de serem buscados para aquela query. Por exemplo:\n",
    "1) 100 produtos mais vendidos, clicados e adicionados ao carrinho numa determinada categoria de produtos\n",
    "2) ....\n",
    "\n",
    "\n",
    "Retrieving mais itens resulta numa performance melhor a custo de recomendacoes mais lentas. Para analizar o trade-off entre performance e velocidade, podemos rodar experimentos para ver se recuperar itens adicionais resulta em recomendacoes mais relevantes para o usuario.\n",
    "\n",
    "## Ranking\n",
    "\n",
    "Dada a lista de itens gerada na etapa anterior, rankeie os melhores produtos usando o modelo de aprendizagem e mostre esses itens rankeados ao usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efce927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
